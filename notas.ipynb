{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capítulo 1 \n",
    "\n",
    "## 2\n",
    "\n",
    " El objetivo de las tareas de PLN no sólo es entender palabras de manera individual, sino también entender su contexto.\n",
    "\n",
    "## 3\n",
    " \n",
    " Recuerda que debes instalar pytorch: `pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121`\n",
    "\n",
    " Hay tres pasos principales que ocurren cuando pasas un texto a un pipeline:\n",
    "\n",
    "    - El texto es preprocesado en un formato que el modelo puede entender.\n",
    "    - La entrada preprocesada se pasa al modelo.\n",
    "    - Las predicciones del modelo son posprocesadas, de tal manera que las puedas entender.\n",
    "\n",
    "### Zero-shot\n",
    "Este pipeline se llama zero-shot porque no necesitas ajustar el modelo con tus datos para usarlo. ¡Puede devolver directamente puntajes de probabilidad para cualquier lista de de etiquetas que escojas!\n",
    "\n",
    "### Generación de texto\n",
    "\n",
    "\n",
    "### Extraer datos importantes de texto, como nombres, empresas, lugares, etc\n",
    "\n",
    "`ner = pipeline(\"ner\", grouped_entities=True)`\n",
    "`ner(\"texto\")`\n",
    "\n",
    "## 4 ¿Cómo funcionan los Transformadores?\n",
    "\n",
    "Todos los modelos de Transformadores mencionados con anterioridad (GPT, BERT, BART, T5, etc.) han sido entrenados como modelos de lenguaje. Esto significa que han sido entrenados con grandes cantidades de texto crudo de una manera auto-supervisada. El aprendizaje auto-supervisado es un tipo de entrenamiento en el que el objetivo se computa automáticamente de las entradas del modelo. ¡Esto significa que no necesitan humanos que etiqueten los datos!\n",
    "\n",
    "Este tipo de modelos desarrolla un entendimiento estadístico del lenguaje sobre el que fue entrenado, pero no es muy útil para tareas prácticas específicas. Por lo anterior, el modelo general preentrenado pasa por un proceso llamado transferencia de aprendizaje (o transfer learning en Inglés). Durante este proceso, el modelo se ajusta de una forma supervisada -- esto es, usando etiquetas hechas por humanos -- para una tarea dada.\n",
    "\n",
    "Un ejemplo de una tarea es predecir la palabra siguiente en una oración con base en las n palabras previas. Esto se denomina modelado de lenguaje causal porque la salida depende de las entradas pasadas y presentes, pero no en las futuras.\n",
    "\n",
    "Desafortunadamente, entrenar un modelo, especialmente uno grande, requiere de grandes cantidades de datos. Esto se vuelve muy costoso en términos de tiempo y recursos de computación, que se traduce incluso en impacto ambiental, como se puede ver en la siguiente gráfica.\n",
    "\n",
    "Ahora imagínate si cada vez que un equipo de investigación, una organización estudiantil o una compañía intentaran entrenar un modelo, tuvieran que hacerlo desde cero. ¡Esto implicaría costos globales enormes e innecesarios!\n",
    "\n",
    "Esta es la razón por la que compartir modelos de lenguaje es fundamental: compartir los pesos entrenados y construir sobre los existentes reduce el costo general y la huella de carbono de la comunidad.\n",
    "\n",
    "El preentrenamiento es el acto de entrenar un modelo desde cero: los pesos se inicializan de manera aleatoria y el entrenamiento empieza sin un conocimiento previo.\n",
    "\n",
    "Este preentrenamiento se hace usualmente sobre grandes cantidades de datos. Por lo anterior, requiere un gran corpus de datos y el entrenamiento puede tomar varias semanas.\n",
    "\n",
    "Por su parte, el ajuste (o fine-tuning) es el entrenamiento realizado después de que el modelo ha sido preentrenado. Para hacer el ajuste, comienzas con un modelo de lenguaje preentrenado y luego realizas un aprendizaje adicional con un conjunto de datos específicos para tu tarea.\n",
    "\n",
    "**¿Por qué no entrenar directamente para la tarea final? Hay un par de razones:**\n",
    "\n",
    "    - El modelo preentrenado ya está entrenado con un conjunto de datos parecido al conjunto de datos de ajuste. De esta manera, el proceso de ajuste puede hacer uso del conocimiento adquirido por el modelo inicial durante el preentrenamiento (por ejemplo, para problemas de PLN, el modelo preentrenado tendrá algún tipo de entendimiento estadístico del idioma que estás usando para tu tarea).\n",
    "    - Dado que el modelo preentrenado fue entrenado con muchos datos, el ajuste requerirá menos datos para tener resultados decentes.\n",
    "    - Por la misma razón, la cantidad de tiempo y recursos necesarios para tener buenos resultados es mucho menor.\n",
    "\n",
    "Este proceso también conseguirá mejores resultados que entrenar desde cero (a menos que tengas una gran cantidad de datos), razón por la cual siempre deberías intentar aprovechar un modelo preentrenado -- uno que esté tan cerca como sea posible a la tarea respectiva -- y ajustarlo.\n",
    "\n",
    "\n",
    "\n",
    "### Arquitectura general\n",
    "\n",
    "1. Codificador - Encoder\n",
    "2. Decodificador - Decoder\n",
    "\n",
    "Cada una de estas partes puede ser usada de manera independiente, dependiendo de la tarea:\n",
    "\n",
    "    Modelos con solo codificadores: Buenos para las tareas que requieren el entendimiento de la entrada, como la clasificación de oraciones y reconocimiento de entidades nombradas.\n",
    "    Modelos con solo decodificadores: Buenos para tareas generativas como la generación de textos.\n",
    "    Modelos con codificadores y decodificadores o Modelos secuencia a secuencia: Buenos para tareas generativas que requieren una entrada, como la traducción o resumen.\n",
    "\n",
    "### Capas de atención\n",
    "\n",
    "Todo lo que tienes que saber es que esta capa va a indicarle al modelo que tiene que prestar especial atención a ciertas partes de la oración que le pasaste (y más o menos ignorar las demás), cuando trabaje con la representación de cada palabra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
